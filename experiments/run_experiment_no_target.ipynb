{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e1b732a-acb3-43e9-bf26-223eee426bc0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Run experiment to synthesize dataset without labelled nodes\n",
    "This notebook compares run the experiment to synthesize a dataset. The synthesied dataset don't have labels therefore the performance is only measured on 'intrinsic' graph properties. The experiment consists of the following steps and is performed 10 time to account for stochasticity\n",
    "\n",
    "- train and calculate the graphsage embedding\n",
    "- train DDPM network and create synthetic nodes.\n",
    "- for the LSTM, MLP and bi-MLP vairants:\n",
    "    - train model and create synthetic edges.\n",
    "    - create synthetic graph\n",
    "    - measure performance\n",
    "    - copy relevant data (synthetic graph, embedding to experiment folder)\n",
    "    - save performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "630a0473-b108-492c-bf8d-fa7b1704c525",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tonpoppe/workspace/tigger_adj_rep/tigger_adj\n"
     ]
    }
   ],
   "source": [
    "# Set root dir\n",
    "import os\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd2e8455-1e29-4aaa-aedf-8e8280faac94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import pickle\n",
    "import pathlib\n",
    "from tigger_package.orchestrator import Orchestrator\n",
    "from tigger_package.metrics.distribution_metrics import compare_metrics\n",
    "from tigger_package.tools import plot_adj_matrix, plot_hist\n",
    "from datetime import datetime, date\n",
    "import networkx as nx \n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "402e9bd5-8097-4f65-8e02-67d500448bda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def copy_data(folder, variant_name, run_nr):\n",
    "    path = pathlib.Path(folder + \"exp_results/no_labels\")\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    #copy synthetic nodes\n",
    "    tmp = pd.read_parquet(folder + 'synth_graph/node_attributes.parquet')\n",
    "    tmp.to_parquet(folder + f'exp_results/no_labels/node_attributes_{variant_name}_run_{run_nr}.parquet')\n",
    "    # copy synthetic edges of synth graph\n",
    "    tmp = pd.read_parquet(folder + 'synth_graph/adjacency.parquet')\n",
    "    tmp.to_parquet(folder + f'exp_results/no_labels/adjacency_{variant_name}_run_{run_nr}.parquet')\n",
    "    # copy synthetic walks\n",
    "    obj = pickle.load(open(folder + 'synth_walks.pickle', 'rb'))\n",
    "    pickle.dump(obj, open(folder + f'exp_results/no_labels/synth_walks_{variant_name}_run_{run_nr}.pickle', 'wb'))\n",
    "    \n",
    "def measure_performance(orchestrator, variant_name):\n",
    "    nodes = orchestrator._load_nodes()\n",
    "    edges = orchestrator._load_edges()\n",
    "    lstm_nodes = pd.read_parquet(folder + 'synth_graph/node_attributes.parquet')\n",
    "    lstm_edges = pd.read_parquet(folder + 'synth_graph/adjacency.parquet')\n",
    "    res = compare_metrics(nodes, edges, lstm_nodes, lstm_edges, variant_name)\n",
    "    return res\n",
    "\n",
    "def run_single_experiment(run_nr, folder):\n",
    "    # create synthetic nodes and embedding\n",
    "    orchestrator = Orchestrator(folder)\n",
    "    nodes_sampled = 0\n",
    "    while nodes_sampled == 0:\n",
    "        orchestrator.create_graphsage_embedding()\n",
    "        orchestrator.train_node_synthesizer()\n",
    "        orchestrator.sample_node_synthesizer()\n",
    "        nodes_sampled = orchestrator._load_synthetic_nodes().shape[0]\n",
    "\n",
    "    res = []\n",
    "    for variant_name in ['LSTM', 'MLP', 'Bi-MLP']:\n",
    "        #train variant and sample edges\n",
    "        target_cnt = 2 * orchestrator._load_edges().shape[0]\n",
    "        orchestrator.init_graphsynthesizer(variant_name, seed=run_nr)\n",
    "        orchestrator.train_graphsyntesizer()\n",
    "        orchestrator.create_synthetic_walks(\n",
    "            synthesizer=orchestrator.graphsynthesizer, \n",
    "            target_cnt=target_cnt\n",
    "        )\n",
    "               \n",
    "        # create synth graph\n",
    "        orchestrator.generate_synth_graph()\n",
    "\n",
    "        #copy relevant data\n",
    "        copy_data(folder, variant_name, run_nr)\n",
    "        \n",
    "        # measure performance\n",
    "        res.append(measure_performance(orchestrator, variant_name))\n",
    "        \n",
    "    res = (res[0]\n",
    "           .merge(res[1], on=['name', 'type', 'metric'])\n",
    "           .merge(res[2], on=['name', 'type', 'metric'])\n",
    "    )\n",
    "    res['run_id'] = run_nr\n",
    "    res['run_tijd'] = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    return res[['name', 'type', 'metric', 'LSTM', 'MLP', 'Bi-MLP','run_id', 'run_tijd']]\n",
    "  \n",
    "def  init_res_dataset(folder):\n",
    "    matching_files = glob.glob(folder + f\"exp_results/no_labels/combined_raw_results_*\")\n",
    "    if len(matching_files)> 0:\n",
    "        max_date = max([int(f.split(\".\")[0][-8:]) for f in matching_files])\n",
    "        res_path = f\"{folder}exp_results/no_labels/combined_raw_results_{max_date}.parquet\"\n",
    "        res = [pd.read_parquet(res_path)]\n",
    "        start_run = res[0]['run_id'].max() + 1\n",
    "    else:\n",
    "        res = []\n",
    "        start_run = 0\n",
    "    return start_run, res\n",
    "\n",
    "def run_experiment(folder, runs=10):\n",
    "    start_run, res = init_res_dataset(folder)\n",
    "    for run_nr in range(start_run, start_run + runs):\n",
    "        print(f\"start processing run {run_nr}\")\n",
    "        res.append(run_single_experiment(run_nr, folder))  \n",
    "        total_df = pd.concat(res, axis=0)\n",
    "        date_str = date.today().strftime(\"%Y%m%d\")\n",
    "        total_df.to_parquet(folder + f\"exp_results/no_labels/combined_raw_results_{date_str}.parquet\")\n",
    "    return total_df  \n",
    "\n",
    "def calculate_Stats(res):\n",
    "    node_attributes = res[res['type']=='node_attributes'].groupby('run_id').agg({'LSTM': 'mean', 'MLP': 'mean', 'Bi-MLP': 'mean', 'type': 'max'}).reset_index()\n",
    "    edge_attributes = res[res['type']=='edge_attributes'].groupby('run_id').agg({'LSTM': 'mean', 'MLP': 'mean', 'Bi-MLP': 'mean', 'type': 'max'}).reset_index()\n",
    "    dif_cluster_coef = res[res['name']=='dif_cluster_coef'][['name', 'LSTM', 'MLP', 'Bi-MLP', 'run_id'] ].rename(columns={'name': 'type'})\n",
    "    delta_widget = res[res['name']=='mean_delta_widget'][['name', 'LSTM', 'MLP', 'Bi-MLP', 'run_id'] ].rename(columns={'name': 'type'})\n",
    "    edge_cnt = (res[(res['type']=='edge_cnt') & (res['name']=='edge_count')].set_index('run_id')[['LSTM', 'MLP', 'Bi-MLP']] -  \n",
    "                res[(res['type']=='edge_cnt') & (res['name']=='orig_edge_count')].set_index('run_id')[['LSTM', 'MLP', 'Bi-MLP']]\n",
    "    )\n",
    "    edge_cnt['type'] = \"Delta_edge_count\"\n",
    "    edge_cnt = edge_cnt.reset_index(names='run_id')\n",
    "    cluster_coef = res[res['name'].str.startswith('dif_')][['name', 'LSTM', 'MLP', 'Bi-MLP', 'run_id'] ].rename(columns={'name': 'type'})\n",
    "    sum_res = pd.concat([node_attributes, edge_attributes, dif_cluster_coef, delta_widget, edge_cnt, cluster_coef], axis=0)\n",
    "    sum_stat = sum_res.groupby('type').mean()\n",
    "    return sum_stat      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fec5a075-a157-4fbb-b709-af69abc5138d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# ERDOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ac32508-439e-4af0-9457-87318459071b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dataset folder and load orchestrator\n",
    "folder = \"data/enron/\"\n",
    "res = run_experiment(folder, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d9f21b3-4050-448e-9ad9-d53357cc0b44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "_, res = init_res_dataset(folder)\n",
    "res = res[0]\n",
    "calculate_Stats(res[res['run_id']!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b921e56b-c9b8-46e0-b23f-c06937fb29bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>MLP</th>\n",
       "      <th>Bi-MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Delta_edge_count</th>\n",
       "      <td>5.5</td>\n",
       "      <td>-1971.500000</td>\n",
       "      <td>-1904.700000</td>\n",
       "      <td>-1404.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dif_cluster_coef</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.283033</td>\n",
       "      <td>0.311139</td>\n",
       "      <td>0.307681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edge_attributes</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.102610</td>\n",
       "      <td>0.120324</td>\n",
       "      <td>0.124587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_delta_widget</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.119216</td>\n",
       "      <td>0.137549</td>\n",
       "      <td>0.067745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_attributes</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.019775</td>\n",
       "      <td>0.019775</td>\n",
       "      <td>0.019775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   run_id         LSTM          MLP       Bi-MLP\n",
       "type                                                            \n",
       "Delta_edge_count      5.5 -1971.500000 -1904.700000 -1404.400000\n",
       "dif_cluster_coef      5.5     0.283033     0.311139     0.307681\n",
       "edge_attributes       5.5     0.102610     0.120324     0.124587\n",
       "mean_delta_widget     5.5     0.119216     0.137549     0.067745\n",
       "node_attributes       5.5     0.019775     0.019775     0.019775"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"data/enron/\"\n",
    "_, res = init_res_dataset(folder)\n",
    "res = res[0]\n",
    "calculate_Stats(res[res['run_id']!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6083ff1-2cf3-4c85-b677-f7198f9d8a45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orchestrator = Orchestrator(folder)\n",
    "edges = orchestrator._load_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2689, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "run_experiment_no_target",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "tigger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
